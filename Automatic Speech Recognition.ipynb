{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Speech Recognition \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step:\n",
    "Extracting the Audio from video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp\n",
    "import librosa as lr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa.display as display\n",
    "import scipy\n",
    "from IPython.display import Audio\n",
    "import pydub\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "import speech_recognition as sr\n",
    "import os\n",
    "import jiwer\n",
    "print(\"Done! necessary libraries are imported\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the audio from video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = mp.VideoFileClip(r\"iceland.mp4\")\n",
    "clip.audio.write_audiofile(r\"converted.wav\")\n",
    "Audio(\"converted.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the audio\n",
    "samples, sample_rate = lr.load(\"converted.wav\")\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.plot(samples[500000: 600000])\n",
    "n_samples = len(samples)\n",
    "print(\"number of samples is:\",n_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot the audio in time domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time = np.arange(0, len(samples))/sample_rate\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.plot(time, samples)\n",
    "print(\"n_time_points:\",len(time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_duration = time.shape[0]/sample_rate\n",
    "print(\"total_duration in seconds :\",total_duration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short time fourier transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =samples\n",
    "stft_feature = lr.amplitude_to_db(np.abs(lr.stft(y, \n",
    "                                                 n_fft=1024,\n",
    "                                                 hop_length=512,\n",
    "                                                 window=scipy.signal.hanning\n",
    "                                                )),\n",
    "                                  ref=np.max\n",
    "                                 )\n",
    "# Plot Spectrogram\n",
    "plt.figure(figsize=(20,3))\n",
    "display.specshow(stft_feature, y_axis='log', x_axis='time')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split the audio into segments of 3-5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound = AudioSegment.from_wav(file=\"converted.wav\")\n",
    "print(\"total duration:\", sound.duration_seconds)\n",
    "\n",
    "# split on silence \n",
    "chunks = split_on_silence(sound, min_silence_len=200, silence_thresh=-34, keep_silence=True)\n",
    "\n",
    "\n",
    "# remerge segments if duration less than 3 second\n",
    "durations_b_m = []\n",
    "for chunk in chunks:\n",
    "    durations_b_m.append(chunk.duration_seconds)\n",
    "\n",
    "\n",
    "duration_minimun = 3\n",
    "chunks_merged = []\n",
    "\n",
    "currently_merging = False\n",
    "merging_chunk = None\n",
    "\n",
    "for j in range(0, len(chunks)):\n",
    "\n",
    "    if not currently_merging:\n",
    "        current_chunk = chunks[j]\n",
    "    else:\n",
    "        current_chunk = merging_chunk + chunks[j]\n",
    "\n",
    "    if current_chunk.duration_seconds > duration_minimun:\n",
    "         chunks_merged.append(current_chunk)\n",
    "         merging_chunk = None\n",
    "         currently_merging = False\n",
    "    else:\n",
    "        currently_merging = True\n",
    "        merging_chunk = current_chunk\n",
    "        \n",
    "# saving the segments after merging as wav file\n",
    "durations = []\n",
    "for i, chunk in enumerate(chunks_merged):\n",
    "    durations.append(chunk.duration_seconds)\n",
    "    chunk.export(\"chunks/chunk{:02d}.wav\".format(i), format=\"wav\")\n",
    "    \n",
    "    \n",
    "print(\"total number of chunks before merging is:\", len(chunks))    \n",
    "print(\"total number of chunks after merging is:\", len(chunks_merged))    \n",
    "    \n",
    "print(\"durations of segments before merging in seconds\")\n",
    "for i, d in enumerate(durations_b_m[0:5]):\n",
    "    print(\"segment %d: %.2f \"%(i,d))\n",
    "    \n",
    "print(\"duration of segments after merging in seconds\")\n",
    "for i, d in enumerate(durations[0:10]):\n",
    "    print(\"segment %d: %.2f \"%(i,d))\n",
    "    \n",
    "#print(\"minimum %.2f sec, maximum %.2f sec\" %(min(durations), max(durations)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(\"chunks/chunk00.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(\"chunks/chunk01.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(\"chunks/chunk03.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe the segments using SpeechRecognition python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"chunks\")\n",
    "sorted_files = sorted(files)\n",
    "sorted_files = sorted_files[1:]\n",
    "#print(\"files:\", sorted_files)\n",
    "\n",
    "r = sr.Recognizer()\n",
    "text_segments = []\n",
    "for file in sorted_files:\n",
    "    audio = sr.AudioFile(\"chunks\"+\"/\"+file)\n",
    "    with audio as source:\n",
    "        audio_file = r.record(source)\n",
    "        result = r.recognize_google(audio_file, language='de-DE')\n",
    "        text_segments.append(result)\n",
    "    print(result)\n",
    "\n",
    "with open('recognized_segments.txt', mode='w') as file:\n",
    "    for item in text_segments:\n",
    "        file.write(\"%s\\n\" % item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transcribed.txt\", \"r\") as test:\n",
    "    refs = test.readlines()\n",
    "with open(\"recognized.txt\", \"r\") as pred:\n",
    "    preds = pred.readlines()\n",
    "\n",
    "reference = refs[0]\n",
    "predicted = preds[1]\n",
    "\n",
    "measures = jiwer.compute_measures(refs[0], preds[1])\n",
    "wer = measures['wer']\n",
    "mer = measures['mer']\n",
    "print(\"Evaluation\")\n",
    "print(\"word error rate is: \", wer*100)\n",
    "print(\"match error rate is: \", mer*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speechrec",
   "language": "python",
   "name": "speechrec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
